import requests
from bs4 import BeautifulSoup
import xml.etree.ElementTree as ET
from xml.dom import minidom
import time
import random
import os
import re
import urllib.parse

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
BASE_URL = "https://—Å—É—à–∏-—Å—Ç—Ä–∏—Ç.—Ä—Ñ/nabory/"
BASE_DOMAIN = "https://—Å—É—à–∏-—Å—Ç—Ä–∏—Ç.—Ä—Ñ"
OUTPUT_DIR = "."
YML_FILE = "sushi_street_catalog.xml"

os.makedirs(OUTPUT_DIR, exist_ok=True)

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

# --- –ö–û–õ–õ–ï–ö–¶–ò–ò ---
COLLECTIONS = {
    "akcii": {"id": "akcii", "name": "–ê–∫—Ü–∏–∏", "url": "https://—Å—É—à–∏-—Å—Ç—Ä–∏—Ç.—Ä—Ñ/akcii/"},
    "promonabory": {"id": "promonabory", "name": "–ü—Ä–æ–º–æ–Ω–∞–±–æ—Ä—ã", "url": "https://—Å—É—à–∏-—Å—Ç—Ä–∏—Ç.—Ä—Ñ/nabory/"},
    "kilogrammovye": {"id": "kilogrammovye", "name": "–ö–∏–ª–æ–≥—Ä–∞–º–º–æ–≤—ã–µ –Ω–∞–±–æ—Ä—ã", "url": "https://—Å—É—à–∏-—Å—Ç—Ä–∏—Ç.—Ä—Ñ/nabory/?item[item_id_parent]=3"},
    "na_dvoih": {"id": "na_dvoih", "name": "–ù–∞ –¥–≤–æ–∏—Ö", "url": "https://—Å—É—à–∏-—Å—Ç—Ä–∏—Ç.—Ä—Ñ/nabory/?item[item_id_parent]=27"},
    "hity": {"id": "hity", "name": "–•–∏—Ç—ã –ø—Ä–æ–¥–∞–∂", "url": "https://—Å—É—à–∏-—Å—Ç—Ä–∏—Ç.—Ä—Ñ/nabory/?item[item_id_parent]=29"},
    "s_filedelfiej": {"id": "s_filedelfiej", "name": "–° —Ñ–∏–ª–∞–¥–µ–ª—å—Ñ–∏–µ–π", "url": "https://—Å—É—à–∏-—Å—Ç—Ä–∏—Ç.—Ä—Ñ/nabory/?item[item_id_parent]=28"},
}

# --- –§–£–ù–ö–¶–ò–ò ---

def log(msg):
    timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
    print(f"[{timestamp}] {msg}")


def make_full_url(path):
    if path.startswith('http'):
        return path
    return BASE_DOMAIN + (path if path.startswith('/') else '/' + path)


def clean_url(url):
    return url.replace('&amp;', '&')


def get_collections(original_name, url, short_description=""):
    colls = []
    name_lower = original_name.lower()
    url_lower = url.lower()
    desc_lower = short_description.lower()

    if any(kw in url_lower for kw in ['akcii', 'ogromnyj', 'vip%20kilogramm']):
        colls.append('akcii')
    if '–Ω–∞-–¥–≤–æ–∏—Ö' in url_lower or 'na-dvoih' in url_lower or '–Ω–∞ –¥–≤–æ–∏—Ö' in name_lower:
        colls.append('na_dvoih')
    if '–∫–∏–ª–æ–≥—Ä–∞–º–º' in name_lower or '–∫–∏–ª–æ' in name_lower:
        colls.append('kilogrammovye')
    if '—Ö–∏—Ç' in name_lower or 'hit' in name_lower:
        colls.append('hity')
    if '–ø—Ä–æ–º–æ–Ω–∞–±–æ—Ä' in name_lower:
        colls.append('promonabory')
    if '—Ñ–∏–ª–∞–¥–µ–ª—å—Ñ–∏—è' in name_lower or '—Ñ–∏–ª–∞–¥–µ–ª—å—Ñ–∏—è' in desc_lower:
        colls.append('s_filedelfiej')
    
    return list(set(colls))


def format_name(original_name):
    clean_name = original_name.strip().strip('"\'')
    return f"–°–µ—Ç \"{clean_name}\""


def extract_weight_and_pieces(description):
    weight = None
    pieces = None
    match = re.search(r'(\d+)\s*–≥—Ä[^\d]*(\d+)\s*—à—Ç', description, re.IGNORECASE)
    if match:
        weight = match.group(1)
        pieces = match.group(2)
    else:
        weight_match = re.search(r'(\d+)\s*–≥—Ä', description, re.IGNORECASE)
        pieces_match = re.search(r'(\d+)\s*—à—Ç', description, re.IGNORECASE)
        if weight_match:
            weight = weight_match.group(1)
        if pieces_match:
            pieces = pieces_match.group(1)
    return weight, pieces


def extract_roll_types_from_description(description):
    cleaned = re.sub(r'–í–µ—Å\s*[\d\w/]+\s*—à—Ç\.*', '', description, flags=re.IGNORECASE)
    cleaned = re.sub(r'\*.*', '', cleaned)
    cleaned = re.sub(r'[^\w\s,.-]', '', cleaned)

    match = re.search(r'–°–æ—Å—Ç–∞–≤\s*[:\-]?\s*(.+)', cleaned, re.IGNORECASE)
    if not match:
        return []

    items_str = match.group(1).strip()
    if not items_str:
        return []

    raw_items = [item.strip() for item in items_str.split(',') if item.strip()]
    roll_types = []
    for item in raw_items:
        item = re.sub(r'^–∏\s+|^–∞\s+—Ç–∞–∫–∂–µ\s+|^—Ç–∞–∫–∂–µ\s+', '', item, flags=re.IGNORECASE).strip()
        if item and len(item) > 3:
            roll_types.append(item)

    return roll_types


def parse_product_page(session, url):
    try:
        response = session.get(url, timeout=10)
        response.raise_for_status()
        response.encoding = 'utf-8'
        soup = BeautifulSoup(response.text, 'html.parser')

        desc_el = soup.find('div', class_='description') or soup.find('div', itemprop='description')
        if desc_el:
            full_desc = ' '.join(desc_el.stripped_strings)
            return full_desc.strip()
        return "–°–æ—Å—Ç–∞–≤ –Ω–µ —É–∫–∞–∑–∞–Ω."
    except Exception as e:
        log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —Å {url}: {e}")
        return "–°–æ—Å—Ç–∞–≤ –Ω–µ —É–∫–∞–∑–∞–Ω."


def parse_catalog_page(session, base_url):
    log(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–∞–ª–æ–≥–∞: {base_url}")
    products = []
    seen_ids = set()  # –î–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
    page_num = 1

    while True:
        if page_num == 1:
            current_url = base_url
        else:
            current_url = f"{base_url}?page={page_num}"

        log(f"‚û°Ô∏è –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {current_url}")

        try:
            response = session.get(current_url, headers=HEADERS, timeout=10)
            if response.status_code == 404:
                log(f"üîö –°—Ç—Ä–∞–Ω–∏—Ü–∞ {current_url} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ (404). –û—Å—Ç–∞–Ω–æ–≤–∫–∞.")
                break

            response.raise_for_status()
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.text, 'html.parser')

            items = soup.find_all('form', class_='js_catalog-item')
            new_items_count = 0

            for item in items:
                try:
                    # üîç –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Å—ã–ª–∫—É
                    link_tag = item.find('a', href=True)
                    link = link_tag['href'] if link_tag else ''
                    full_link = make_full_url(link)
                    full_link = clean_url(full_link)

                    # üîç –ù–∞–∑–≤–∞–Ω–∏–µ (–Ω—É–∂–Ω–æ –î–û –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–µ–π)
                    meta_name = item.find('meta', {'name': 'name'})
                    original_name = meta_name['content'].strip() if meta_name else '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è'

                    # üîé 1. –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å product_id –∏–∑ URL
                    product_id = None
                    if 'product_id=' in full_link:
                        try:
                            parsed = urllib.parse.urlparse(full_link)
                            query = urllib.parse.parse_qs(parsed.query)
                            product_id = query.get('product_id', [None])[0]
                        except Exception as e:
                            log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ product_id –∏–∑ URL: {e}")

                    # üîé 2. –†–µ–∑–µ—Ä–≤: item_id –∏–∑ input
                    item_id_input = item.find('input', {'name': 'item_id'})
                    item_id = item_id_input['value'].strip() if item_id_input else None

                    # ‚úÖ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: product_id > item_id
                    base_vendor_code = product_id or item_id
                    if not base_vendor_code:
                        log(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω —Ç–æ–≤–∞—Ä: –Ω–µ—Ç vendorCode (—Å—Å—ã–ª–∫–∞: {full_link})")
                        continue

                    # üîÅ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π vendor_code
                    vendor_code = base_vendor_code
                    counter = 1
                    original_vendor_code = vendor_code

                    while vendor_code in seen_ids:
                        log(f"üîÅ –î—É–±–ª—å: vendorCode={original_vendor_code}, –ù–∞–∑–≤–∞–Ω–∏–µ='{original_name}', URL={full_link}")
                        vendor_code = f"{original_vendor_code}_{counter}"
                        counter += 1
                        if counter > 10:  # –ó–∞—â–∏—Ç–∞ –æ—Ç –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è
                            log(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥—É–±–ª–µ–π –¥–ª—è {original_vendor_code}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                            continue

                    # ‚úÖ –¢–µ–ø–µ—Ä—å vendor_code —É–Ω–∏–∫–∞–ª–µ–Ω

                    # üîç –¶–µ–Ω–∞
                    price_tag = item.find('span', class_='price-fixed')
                    price = price_tag.text.strip() if price_tag else ''
                    price = re.sub(r'\D', '', price)

                    # üîç –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    img_tag = item.find('img', itemprop='image')
                    image = img_tag['src'] if img_tag else ''
                    full_image = make_full_url(image)

                    # üîç –û–ø–∏—Å–∞–Ω–∏–µ
                    desc_el = item.find('div', class_='description')
                    short_desc = ' '.join(desc_el.stripped_strings).strip() if desc_el else ''

                    # üîç –ö–æ–ª–ª–µ–∫—Ü–∏–∏
                    collections = get_collections(original_name, full_link, short_desc)

                    # üîç –í–µ—Å –∏ —à—Ç—É–∫–∏
                    weight, pieces = extract_weight_and_pieces(short_desc)

                    # üîç –¢–∏–ø—ã —Ä–æ–ª–ª–æ–≤
                    roll_types = extract_roll_types_from_description(short_desc)

                    product = {
                        'id': vendor_code,
                        'vendorCode': vendor_code,
                        'name': format_name(original_name),
                        'original_name': original_name,
                        'price': price,
                        'url': full_link,
                        'image': full_image,
                        'short_description': short_desc,
                        'collections': collections,
                        'weight': weight,
                        'pieces': pieces,
                        'roll_types': roll_types
                    }

                    products.append(product)
                    seen_ids.add(vendor_code)
                    new_items_count += 1

                except Exception as e:
                    log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–æ–≤–∞—Ä–∞: {e}")
                    continue

            log(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {new_items_count} —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num}")

            if new_items_count == 0:
                log("üîö –ë–æ–ª—å—à–µ –Ω–µ—Ç —Ç–æ–≤–∞—Ä–æ–≤. –û—Å—Ç–∞–Ω–æ–≤–∫–∞.")
                break

            page_num += 1
            time.sleep(random.uniform(1.5, 3.0))

        except Exception as e:
            log(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {current_url}: {e}")
            break

    log(f"üì¶ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –≤—Å–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º")
    return products


def generate_yml(products):
    log("üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è YML-—Ñ–∏–¥–∞...")

    # --- –°–æ–±–∏—Ä–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫–∏ –¥–ª—è –∫–æ–ª–ª–µ–∫—Ü–∏–π ---
    collection_images = {}
    for prod in products:
        for coll_id in prod['collections']:
            if coll_id in COLLECTIONS and coll_id not in collection_images:
                collection_images[coll_id] = prod['image']

    # --- –°–æ–∑–¥–∞—ë–º XML ---
    yml = ET.Element('yml_catalog', date=time.strftime("%Y-%m-%dT%H:%M:%S"))
    shop = ET.SubElement(yml, 'shop')
    ET.SubElement(shop, 'name').text = '–°—É—à–∏ –°—Ç—Ä–∏—Ç'
    ET.SubElement(shop, 'company').text = '–°—É—à–∏ –°—Ç—Ä–∏—Ç –†—è–∑–∞–Ω—å'
    ET.SubElement(shop, 'url').text = BASE_DOMAIN
    ET.SubElement(shop, 'platform').text = 'OpenCart'

    currencies = ET.SubElement(shop, 'currencies')
    ET.SubElement(currencies, 'currency', id='RUB', rate='1')

    categories = ET.SubElement(shop, 'categories')
    cat = ET.SubElement(categories, 'category', id='1')
    cat.text = '–°—É—à–∏ –∏ —Ä–æ–ª–ª—ã'

    offers = ET.SubElement(shop, 'offers')

    session = requests.Session()
    session.headers.update(HEADERS)

    for i, prod in enumerate(products, 1):
        log(f"‚û°Ô∏è ({i}/{len(products)}) –ü–∞—Ä—Å–∏–Ω–≥ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {prod['name']}")

        full_description = parse_product_page(session, prod['url'])
        if not full_description or full_description == "–°–æ—Å—Ç–∞–≤ –Ω–µ —É–∫–∞–∑–∞–Ω.":
            full_description = prod['short_description'] or f"–°–æ—Å—Ç–∞–≤: {prod['original_name']}. –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –Ω–∞ —Å–∞–π—Ç–µ."

        if len(full_description) < 20:
            full_description = f"–°–æ—Å—Ç–∞–≤: {prod['original_name']}. –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –Ω–∞ —Å–∞–π—Ç–µ."

        offer = ET.SubElement(offers, 'offer', id=prod['id'], available='true')
        ET.SubElement(offer, 'name').text = prod['name']
        ET.SubElement(offer, 'vendorCode').text = prod['vendorCode']

        # üî• URL —Å CDATA —á–µ—Ä–µ–∑ –∑–∞–≥–ª—É—à–∫—É
        url_elem = ET.SubElement(offer, 'url')
        url_elem.text = f"__CDATA_START__{prod['url']}__CDATA_END__"

        ET.SubElement(offer, 'price').text = prod['price'] or '0'
        ET.SubElement(offer, 'currencyId').text = 'RUB'
        ET.SubElement(offer, 'categoryId').text = '1'
        if prod['image']:
            ET.SubElement(offer, 'picture').text = prod['image']
        if full_description:
            desc_elem = ET.SubElement(offer, 'description')
            desc_elem.text = full_description
        sales_notes = f"–ê—Ä—Ç–∏–∫—É–ª: {prod['vendorCode']}. –î–æ—Å—Ç–∞–≤–∫–∞ –ø–æ –†—è–∑–∞–Ω–∏."
        ET.SubElement(offer, 'sales_notes').text = sales_notes

        # üî• collectionId
        for coll_id in prod['collections']:
            if coll_id in COLLECTIONS:
                ET.SubElement(offer, 'collectionId').text = coll_id

        if prod['weight']:
            ET.SubElement(offer, 'param', name='weight').text = prod['weight']
        if prod['pieces']:
            ET.SubElement(offer, 'param', name='pieces').text = prod['pieces']

        for roll_type in prod['roll_types']:
            ET.SubElement(offer, 'param', name='roll_type').text = roll_type

        time.sleep(random.uniform(0.5, 1.0))

    # --- –ë–ª–æ–∫ –∫–æ–ª–ª–µ–∫—Ü–∏–π ---
    collections_elem = ET.SubElement(shop, 'collections')
    for coll_id, coll_data in COLLECTIONS.items():
        coll = ET.SubElement(collections_elem, 'collection', id=coll_id)
        ET.SubElement(coll, 'name').text = coll_data['name']

        url_elem = ET.SubElement(coll, 'url')
        url_elem.text = f"__CDATA_START__{coll_data['url']}__CDATA_END__"

        ET.SubElement(coll, 'description').text = f"–ù–∞–±–æ—Ä—ã –∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {coll_data['name']}"
        if coll_id in collection_images:
            ET.SubElement(coll, 'picture').text = collection_images[coll_id]

    # --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è XML ---
    rough_string = ET.tostring(yml, 'utf-8')
    reparsed = minidom.parseString(rough_string)

    # pretty xml
    pretty_xml = reparsed.toprettyxml(indent="  ", newl="\n")
    lines = [line for line in pretty_xml.split('\n') if line.strip()]
    xml_content = '\n'.join(lines)

    # üî• –ó–∞–º–µ–Ω—è–µ–º –∑–∞–≥–ª—É—à–∫–∏ –Ω–∞ CDATA
    xml_content = xml_content.replace('__CDATA_START__', '<![CDATA[')
    xml_content = xml_content.replace('__CDATA_END__', ']]>')

    # üî• –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞–∑–±–∏—Ç—ã–µ CDATA
    import re
    xml_content = re.sub(
        r'<url><!\[CDATA\[(.*?)\]\]></url>',
        r'<url><![CDATA[\1]]></url>',
        xml_content
    )

    # ‚úÖ –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ XML –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å <?xml ...>
    if not xml_content.startswith('<?xml'):
        xml_content = '<?xml version="1.0" encoding="utf-8"?>\n' + xml_content

    with open(YML_FILE, 'w', encoding='utf-8') as f:
        f.write(xml_content)

    log(f"‚úÖ –§–∏–¥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {YML_FILE}")


# --- –û–°–ù–û–í–ù–û–ô –ö–û–î ---
if __name__ == "__main__":
    log("üöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä—Å–µ—Ä–∞ —Å—É—à–∏-—Å—Ç—Ä–∏—Ç.—Ä—Ñ")

    session = requests.Session()
    session.headers.update(HEADERS)

    # –ü–∞—Ä—Å–∏–º –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    all_products = parse_catalog_page(session, BASE_URL)

    if all_products:
        generate_yml(all_products)
        log(f"üéâ –ì–æ—Ç–æ–≤–æ! –í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(all_products)}")
    else:
        log("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–±—Ä–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞.")

    session.close()
